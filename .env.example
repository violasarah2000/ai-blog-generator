# AI Blog Generator Configuration

# Model Configuration
# Options: "ollama" or "huggingface"
MODEL_BACKEND=ollama

# If using Ollama
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=stablelm-zephyr:3b

# If using HuggingFace
HUGGINGFACE_MODEL_NAME=stabilityai/stablelm-zephyr-3b

# Generation Parameters
MAX_NEW_TOKENS=500
GEN_TEMPERATURE=0.7
GEN_TOP_P=0.9
MAX_TOPIC_LEN=200

# Rate Limiting
RATE_LIMIT_HOURLY=100
RATE_LIMIT_MINUTELY=10

# Flask Configuration
FLASK_ENV=development
DEBUG=False
